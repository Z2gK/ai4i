<?xml version="1.0" ?>
<cherrytree>
	<bookmarks list="2,18,21,31"/>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Intro to Python for Data Science" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542451468.54" ts_lastsave="1542454833.41" unique_id="1">
		<rich_text>





</rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Numpy basics" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542451543.36" ts_lastsave="1542715128.68" unique_id="2">
			<rich_text scale="h1">Creating numpy arrays</rich_text>
			<rich_text>

Lists can be converted to numpy arrays, but the numpy package has to be imported first.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Arithmetic operations</rich_text>
			<rich_text>

Arithmetic operations can be applied directly to numpy arrays.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Subsetting and Indexing</rich_text>
			<rich_text>

Numpy arrays can be subsetted and indexed.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">2D numpy arrays</rich_text>
			<rich_text>

2D numpy arrays can be created. These are just list of lists.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Basic statistical functions</rich_text>
			<rich_text>

Numpy also has basic statistical methods for objects, such as the following:
• numpy.mean()
• numpy.median()
• numpy.std()
• numpy.corrcoeff(... ,...)


</rich_text>
			<rich_text weight="heavy">Check what this numpy function does. This appeared in the Importing Data in Python Part 1 section about HDF5 data.</rich_text>
			<rich_text>
</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>




</rich_text>
			<codebox char_offset="112" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import numpy as np
baseball = [180, 215, 210, 210, 188, 176, 209, 200]
np_baseball = np.array(baseball)</codebox>
			<codebox char_offset="202" frame_height="190" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create array from height with correct units: np_height_m
np_height_m = np.array(height) * 0.0254

# Create array from weight with correct units: np_weight_kg
np_weight_kg = np.array(weight) * 0.453592

# Calculate the BMI: bmi
bmi = np_weight_kg / np_height_m ** 2
</codebox>
			<codebox char_offset="274" frame_height="310" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create the light array
light = bmi &lt; 21

# Print out light
print(light)

# Print out BMIs of all baseball players whose BMI is below 21
print(bmi[light])

# Print out the weight at index 50
print(np_weight[50])

# Print out sub-array of np_height: index 100 up to and including index 110
print(np_height[100:111])</codebox>
			<codebox char_offset="357" frame_height="160" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">baseball = [[180, 78.4],
            [215, 102.7],
            [210, 98.5],
            [188, 75.2]]

# Create a 2D numpy array from baseball: np_baseball
np_baseball = np.array(baseball)
</codebox>
			<codebox char_offset="657" frame_height="70" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Set time vector
time = np.arange(0, 1, 1/num_samples)
</codebox>
		</node>
	</node>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Intermediate Python for Data Science" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542453323.53" ts_lastsave="1542457044.44" unique_id="3">
		<rich_text></rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Basic plotting with matplotlib" prog_lang="custom-colors" readonly="False" tags="matplotlib" ts_creation="1542453435.11" ts_lastsave="1543310707.55" unique_id="4">
			<rich_text scale="h1">Line and scatter plots</rich_text>
			<rich_text>

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


Plotting using pandas module. This also seem to work, from what it seems in other courses.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

The plotting function can be called directly from the data frame as well, through the plot method. This usage is seen in the Cleaning Data in Python chapter.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>
</rich_text>
			<codebox char_offset="24" frame_height="250" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import matplotlib.pyplot as plt

# Make a line plot: year on the x-axis, pop on the y-axis
plt.plot(year,pop)

# Display the plot with plt.show() and then clean up
plt.show()
plt.clf()

# Change the line plot below to a scatter plot
plt.scatter(gdp_cap, life_exp)
</codebox>
			<codebox char_offset="120" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
import pandas as pd

# Plot 'Age' variable in a histogram
# data is a data series
pd.DataFrame.hist(data)
plt.show()
</codebox>
			<codebox char_offset="282" frame_height="205" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">

# Plot the histogram
# rot is for rotation of the x axis labels
# logx and logy are for specify if the axes need to be on the log scale
df['Existing Zoning Sqft'].plot(kind='hist', rot=70, logx=True, logy=True)

# Create the boxplot
# This is a whisker and tail plot
# rot is for rotating the x axis label
# The value plotted is in the column argument, category is by Borough
df.boxplot(column='initial_cost', by='Borough', rot=90)

</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Pandas basics" prog_lang="custom-colors" readonly="False" tags="pandas" ts_creation="1542453803.32" ts_lastsave="1543081828.77" unique_id="5">
			<rich_text scale="h1">Building Pandas data frames</rich_text>
			<rich_text>

Pandas data frames can be built from lists with the aid of dictionaries.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Row labels can be specified.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


In an Importing Data in Python Part 2 exercise, a pandas  data frame can also be built from a list of dictionaries

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


</rich_text>
			<rich_text scale="h1">Reading CSV data into data frames</rich_text>
			<rich_text>

Reading csv files can be done through read_csv method. An optional </rich_text>
			<rich_text weight="heavy">chunksize argument </rich_text>
			<rich_text>can be added to read the data in chunks. The index_col argument is used to specify the column in the file used for the row label, if any.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Basic square bracket indexing</rich_text>
			<rich_text>

Dataframes can be indexed and selected. Single brackets give a Series. Double brackets give a DataFrame. With just simple square bracketting, we cannot select both rows and columns at once though. Note that for row data selection, the use of row labels is not supported with this method.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


</rich_text>
			<rich_text scale="h1">More advanced loc and iloc indexing</rich_text>
			<rich_text>

If we want 2D functionalities we need to use the loc and iloc methods. 

We can select row data using the row labels

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

We can query individual elements, and take their intersection. To select all values, as usual, the “:” operator is used.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Seen in Importing Data in Python Part 2 exercise, a new way to reference

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


</rich_text>
			<rich_text scale="h1">Logical subsetting</rich_text>
			<rich_text>

We can select data based on logical criteria using bracket subsetting. These return data frames.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Note special numpy logical functions have to be used when boolean operations are needed.
• numpy.logical_and()
• numpy.logical_or()
• numpy.logical_not()
</rich_text>
			<codebox char_offset="103" frame_height="295" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Pre-defined lists
names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']
dr =  [True, False, False, False, True, True, True]
cpc = [809, 731, 588, 18, 200, 70, 45]

# Import pandas as pd
import pandas as pd

# Create dictionary my_dict with three key:value pairs: my_dict
my_dict = {'country':names,'drives_right':dr,'cars_per_cap':cpc}

# Build a DataFrame cars from my_dict: cars
cars = pd.DataFrame(my_dict)
</codebox>
			<codebox char_offset="136" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Definition of row_labels
row_labels = ['US', 'AUS', 'JAP', 'IN', 'RU', 'MOR', 'EG']

# Specify row labels of cars
cars.index = row_labels</codebox>
			<codebox char_offset="256" frame_height="175" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import package
import pandas as pd

# Build DataFrame of tweet texts and languages
df = pd.DataFrame(tweets_data, columns=[&quot;text&quot;,&quot;lang&quot;])

# Print head of DataFrame
print(df.head())
</codebox>
			<codebox char_offset="520" frame_height="115" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import pandas as pd
import pandas as pd

# Fix import by including index_col
cars = pd.read_csv('cars.csv',index_col = 0)</codebox>
			<codebox char_offset="843" frame_height="280" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Print out country column as Pandas Series
print(cars['country'])

# Print out country column as Pandas DataFrame
print(cars[['country']])

# Print out DataFrame with country and drives_right columns
print(cars[['country','drives_right']])

# Print out first 3 observations
print(cars[0:3])

# Print out fourth, fifth and sixth observation
print(cars[3:6])</codebox>
			<codebox char_offset="1002" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Print out observation for Japan - this is pandas Series
print(cars.loc['JAP'])

# Print out observations for Australia and Egypt - this is a DataFrame
print(cars.loc[['AUS','EG']])</codebox>
			<codebox char_offset="1127" frame_height="190" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Print out drives_right value of Morocco - this should be a value
# If &quot;MOR&quot; is replaced by :, this would be a Series
print(cars.loc['MOR','drives_right'])

# Print sub-DataFrame
print(cars.loc[['RU','MOR'],['country','drives_right']])

# Print out cars_per_cap and drives_right as DataFrame
print(cars.loc[:,['cars_per_cap','drives_right']])</codebox>
			<codebox char_offset="1204" frame_height="40" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">df.ix[:, 0:1]</codebox>
			<codebox char_offset="1326" frame_height="385" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import pandas as pd
cars = pd.read_csv('cars.csv', index_col = 0)

# Convert code to a one-liner - the argument is a True/False Series
sel = cars[cars['drives_right']]


# Create car_maniac: observations that have a cars_per_cap over 500
cpc = cars['cars_per_cap']
many_cars = cpc &gt; 500
car_maniac = cars[many_cars]

# Need to import numpy and use the logical operators for more complex logic
import numpy as np
between = np.logical_and(cpc &gt; 100, cpc &lt; 500)
medium = cars[between]


</codebox>
		</node>
	</node>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Python Data Science Toolbox Part 1" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542457044.44" ts_lastsave="1542458096.74" unique_id="6">
		<rich_text></rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Lambda functions and its uses" prog_lang="custom-colors" readonly="False" tags="lambda, map, reduce, filter" ts_creation="1542457086.4" ts_lastsave="1542458233.21" unique_id="7">
			<rich_text scale="h1">Lambda functions</rich_text>
			<rich_text>

Lambda functions need to be enclosed in round brackets when being defined. They are defined in the format:

lambda &lt;inputs&gt;: &lt;actions on inputs and value to return&gt;

Only one “line” is permitted for the lambda function definition.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


</rich_text>
			<rich_text scale="h1">Map</rich_text>
			<rich_text>

Map function takes a function and a sequence as its arguments and applies the function to every member of the sequence, and returns the resulting sequence.

Syntax: map(func, seq)
Returns: a sequence

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Filter</rich_text>
			<rich_text>

Filter function takes a function and a sequence as its input, and returns a sequence of members from the original sequence. Filter takes the function and evaluates it on every member of the input sequence. Those that evaluate to True will be returned in the output sequence.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text> 

</rich_text>
			<rich_text scale="h1">Reduce</rich_text>
			<rich_text>

Reduce function takes a function and a sequence as its arguments.

The input function needs to take two inputs and return return one output. Reduce takes the first two elements of the sequence and applies the function. Using the output of the function as one of the input, and the third element and the other input, the function is applied on these two elements. This is repeated until all the elements of the sequence are exhausted.

Note that reduce needs to be imported from functools.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


</rich_text>
			<codebox char_offset="250" frame_height="145" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Define echo_word as a lambda function: echo_word
echo_word = (lambda word1, echo: word1 * echo)

# Call echo_word: result
result = echo_word(&quot;hey&quot;,5)
</codebox>
			<codebox char_offset="460" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings: spells
spells = [&quot;protego&quot;, &quot;accio&quot;, &quot;expecto patronum&quot;, &quot;legilimens&quot;]

# Use map() to apply a lambda function over spells: shout_spells
shout_spells = map(lambda s: s+&quot;!!!&quot;, spells)
</codebox>
			<codebox char_offset="747" frame_height="145" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings: fellowship
fellowship = ['frodo', 'samwise', 'merry', 'pippin', 'aragorn', 'boromir', 'legolas', 'gimli', 'gandalf']

# Use filter() to apply a lambda function over fellowship: result
result  = filter(lambda s: len(s)&gt;6, fellowship)
</codebox>
			<codebox char_offset="1249" frame_height="190" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import reduce from functools
from functools import reduce

# Create a list of strings: stark
stark = ['robb', 'sansa', 'arya', 'brandon', 'rickon']

# Use reduce() to apply a lambda function over stark: result
result = reduce(lambda item1, item2: item1+item2,stark)
</codebox>
		</node>
	</node>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Python Data Science Toolbox Part 2" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542458096.74" ts_lastsave="1542554806.19" unique_id="8">
		<rich_text></rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Iterators" prog_lang="custom-colors" readonly="False" tags="iterators, iterables" ts_creation="1542458105.24" ts_lastsave="1542459579.8" unique_id="9">
			<rich_text scale="h1">Iterators and iterables</rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h2">Iterables</rich_text>
			<rich_text>

Examples of iterables include 
• lists 
• strings 
• dictionaries
• file connections, etc.

Iterables can be iterated by directly using them in a for loop

for item in &lt;iterable&gt;:
    &lt;do things on item&gt;

They can be explicitly turned into a iterator object by applying iter() method. Under the hood, this is what the for loop is doing to iterables.


</rich_text>
			<rich_text scale="h2">Iterators</rich_text>
			<rich_text>

Iterators are objects that can be created from iterables via the iter method. Iterators have an associated next() method.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

This works on file connections as well, though we normally just use “for line in file:”

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Calling next() when there are no values left to return would give us a StopIteration error.

The splat operator * would return all the elements in the iterator all at once.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

An iterator can be created from a range object as well. The range function does not actually create a list in memory, which is good when we need to iterate over a large range.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>



</rich_text>
			<codebox char_offset="522" frame_height="220" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings: flash
flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']
# Create an iterator for flash: superspeed
superspeed = iter(flash)

# Print each item from the iterator
print(next(superspeed))
print(next(superspeed))
print(next(superspeed))
print(next(superspeed))
</codebox>
			<codebox char_offset="614" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">file = open(&quot;file.txt&quot;)
it = iter(file)
print(next(it))
print(next(it))
...</codebox>
			<codebox char_offset="791" frame_height="160" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">word = &quot;Data&quot;
it = iter(word)
print(*it)
# Output:
# D a t a

# Doing this again would return an error
print(*it)</codebox>
			<codebox char_offset="971" frame_height="205" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create an iterator for range(10 ** 100): googol
googol = iter(range(10 ** 100))

# Print the first 5 values from googol - no errors here
print(next(googol))
print(next(googol))
print(next(googol))
print(next(googol))
print(next(googol))
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Enumerate" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542458136.12" ts_lastsave="1542460224.71" unique_id="10">
			<rich_text scale="h1">Enumerate</rich_text>
			<rich_text>

The enumerate function takes any iterable as its argument and returns a special enumerate object. The elements of this object consists of pairs with the index of the original member of the iterable, and the iterable itself.

This special enumerate object can be converted into a list.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


This enumerate object </rich_text>
			<rich_text weight="heavy">itself is an iterable</rich_text>
			<rich_text> and can be iterated over. The start index can be changed as well

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>
</rich_text>
			<codebox char_offset="297" frame_height="340" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings: mutants
mutants = ['charles xavier', 
            'bobby drake', 
            'kurt wagner', 
            'max eisenhardt', 
            'kitty pryde']

# Create a list of tuples: mutant_list
mutant_list = list(enumerate(mutants))

# Print the list of tuples
print(mutant_list)

# Output
# [(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]
</codebox>
			<codebox char_offset="411" frame_height="310" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Unpack and print the tuple pairs
for index1, value1 in enumerate(mutants):
    print(index1, value1)
# Output
# 0 charles xavier
# 1 bobby drake
# 2 kurt wagner
# 3 max eisenhardt
# 4 kitty pryde

# Change the start index
for index2, value2 in enumerate(mutants, start=1):
    print(index2, value2)


</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Zip" prog_lang="custom-colors" readonly="False" tags="zip" ts_creation="1542458149.6" ts_lastsave="1542461575.85" unique_id="11">
			<rich_text scale="h1">Zip</rich_text>
			<rich_text>

Zip accepts an arbitrary number of iterables as its argument and returns a special zip object, which is also </rich_text>
			<rich_text weight="heavy">an iterator of tuples</rich_text>
			<rich_text>. Zip itself </rich_text>
			<rich_text weight="heavy">is an iterable</rich_text>
			<rich_text>.

Zip objects can be convert to a list of tuples.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

They can also be iterated over in a for loop.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

The zip object can be unpacked using the splat operator *.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

But this will exhaust the zip object and we have to create it again.</rich_text>
			<codebox char_offset="214" frame_height="280" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">mutants = ['charles xavier', 'bobby drake' ...]
aliases = ['prof x', 'iceman', ...]
powers = ['telepathy','thermokinesis',...]

# Create a list of tuples: mutant_data
mutant_data = list(zip(mutants, aliases, powers))

# Print the list of tuples
print(mutant_data)

# [('charles xavier', 'prof x', 'telepathy'), ('bobby drake', 'iceman', 'thermokinesis'), ('kurt wagner', 'nightcrawler', 'teleportation'), ('max eisenhardt', 'magneto', 'magnetokinesis'), ('kitty pryde', 'shadowcat', 'intangibility')]</codebox>
			<codebox char_offset="264" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Unpack the zip object and print the tuple values
for value1,value2,value3 in mutant_zip:
    print(value1, value2, value3)
</codebox>
			<codebox char_offset="327" frame_height="205" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a zip object from mutants and powers: z1
z1 = zip(mutants,powers)

# Print the tuples in z1 by unpacking with *
print(*z1)

# ('charles xavier', 'telepathy') ('bobby drake', 'thermokinesis') ('kurt wagner', 'teleportation') ('max eisenhardt', 'magnetokinesis') ('kitty pryde', 'intangibility')
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="List Comprehension" prog_lang="custom-colors" readonly="False" tags="list comprehension" ts_creation="1542458171.07" ts_lastsave="1542461873.74" unique_id="12">
			<rich_text scale="h1">Basic list comprehension</rich_text>
			<rich_text>

The list comprehension syntax generates a list </rich_text>
			<rich_text weight="heavy">from an iterable object</rich_text>
			<rich_text>. It applies a certain action to each member of the list. The output of that action would be the members of the new list.

List comprehension </rich_text>
			<rich_text weight="heavy">constructs the entire list and stores it in memory</rich_text>
			<rich_text>.

[ &lt;output expression&gt; for &lt;iterator variable&gt; in &lt;iterable&gt; ]

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

List comprehension are more efficient than for loops.

List comprehensions can replace nested for loops as well.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Advanced list comprehension</rich_text>
			<rich_text>

Conditionals can be added on at the iterable side.

[ &lt;output expression&gt; for &lt;iterator variable&gt; in &lt;iterable&gt; </rich_text>
			<rich_text weight="heavy">if &lt;condition&gt;</rich_text>
			<rich_text>]

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Or they can be added at the output expression side.

[ &lt;output expression&gt; </rich_text>
			<rich_text weight="heavy">if &lt;condition&gt;</rich_text>
			<rich_text> for &lt;iterator variable&gt; in &lt;iterable&gt;]

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>
</rich_text>
			<codebox char_offset="354" frame_height="70" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create list comprehension: squares
squares = [i*i for i in range(0,10)]</codebox>
			<codebox char_offset="471" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">pairs_2 = [(num1, num2) for num1 in range(0,2) for num2 in range(6,8)
print(pairs_2)
# Output
# [(0, 6), (0, 7), (1, 6), (1, 7)]
</codebox>
			<codebox char_offset="632" frame_height="145" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings: fellowship
fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']

# Create list comprehension: new_fellowship
new_fellowship = [member for member in fellowship if len(member)&gt;= 7]
</codebox>
			<codebox char_offset="765" frame_height="85" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create list comprehension: new_fellowship
new_fellowship = [member if len(member)&gt;=7 else &quot;&quot; for member in fellowship]
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Generators" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542458177.9" ts_lastsave="1542462803.86" unique_id="13">
			<rich_text scale="h1">Generators from list comprehension syntax</rich_text>
			<rich_text> 

A basic generator can be obtained using the same syntax as list comprehension, except that we use () instead of [].

This creates a generator object which can be iterated over in a for loop. 

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

The next() function can also be applied to generator objects. Lazy evaluation - helps when working with large sequences and we don't want to store the entire sequence memory.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Conditional expressions that work for list comprehension also apply for generators.


</rich_text>
			<rich_text scale="h1">Generators from generator functions</rich_text>
			<rich_text>

Generator functions produce generator objects and are defined using def just like functions. instead of using return, we used yield in a generator function.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>




</rich_text>
			<codebox char_offset="237" frame_height="205" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings: lannister
lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']

# Create a generator object: lengths
lengths = (len(person) for person in lannister)

# Iterate over and print the values in lengths
for value in lengths:
    print(value)
</codebox>
			<codebox char_offset="416" frame_height="280" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create generator object: result
result = (num for num in range(0,31))

# Print the first 5 values
print(next(result))
print(next(result))
print(next(result))
print(next(result))
print(next(result))

# Print the rest of the values
for value in result:
    print(value)
</codebox>
			<codebox char_offset="700" frame_height="325" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Create a list of strings
lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']

# Define generator function get_lengths
def get_lengths(input_list):
    &quot;&quot;&quot;Generator function that yields the
    length of the strings in input_list.&quot;&quot;&quot;

    # Yield the length of a string
    for person in input_list:
        yield(len(person))

# Print the values generated by get_lengths()
for value in get_lengths(lannister):
    print(value)
</codebox>
		</node>
	</node>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Importing Data in Python Part 1" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542554806.19" ts_lastsave="1542987986.82" unique_id="14">
		<rich_text></rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Numpy" prog_lang="custom-colors" readonly="False" tags="numpy data import" ts_creation="1542554816.8" ts_lastsave="1542555952.79" unique_id="15">
			<rich_text scale="h1">Basic numpy data import</rich_text>
			<rich_text>

Importing as a numpy array. The object data is of type numpy.ndarray

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

delimiter: what delimiter is used for the data. Tab is \t
skiprows: how many header rows to skip at the start
usecols: which columns to import - in the example above, we are importing the first and third columns
dtype: what data type to use for all the data - in  the example above everything is imported as strings

Numpy is fine if all data is of the same type, but loadtxt breaks down if data is of mixed type.

</rich_text>
			<rich_text scale="h1">genfromtxt function</rich_text>
			<rich_text>

The numpy.genfromtxt() function is preferable for mixed type data.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

names: whether there is a header row.
dtype: if set to None, genfromtxt will figure out what each column should be

Here the object data is a structured array, where each element of this 1D array represents a row of the data

data[&lt;number&gt;] accesses a row
data[&lt;column label&gt;] accesses a column

</rich_text>
			<rich_text scale="h1">recfromcsv function</rich_text>
			<rich_text>

There is another function numpy.recfromcsv() that behaves similar to genfromtxt(). Its default arguments are as above in the genfromtxt() example, so we do not need to pass recfromcsv() any further arguments. The default dtype is None.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<codebox char_offset="95" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import numpy as np
filename = &quot;file.txt&quot;
data = np.loadtxt(file, delimiter=&quot;,&quot;, skiprows=1, usecols=[0,2], dtype=str)</codebox>
			<codebox char_offset="602" frame_height="55" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)</codebox>
			<codebox char_offset="1159" frame_height="55" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">file = 'titanic.csv'
d=np.recfromcsv(file)
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Pandas" prog_lang="custom-colors" readonly="False" tags="pandas flat file import" ts_creation="1542554823.12" ts_lastsave="1542714218.39" unique_id="16">
			<rich_text scale="h1">Basic pandas data import</rich_text>
			<rich_text>

Flat files can be imported in pandas.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

nrows: number of rows to import
header: if set to None, there is no header row in the flat file. If set to 0, there is a header row and its column names are taken as default. The default behaviour is 0. Otherwise, the column names need to be specified in an argument names, a list of column names to use in the resulting data frame.
sep: field separator if not comma
comment: comment symbol, if used in the data frame
na_values: string used in flat file to indicate NA or NaN

</rich_text>
			<codebox char_offset="65" frame_height="220" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import pandas as pd
import pandas as pd

# Assign the filename: file
file = 'titanic.csv'

# Read the file into a DataFrame: df
df = pd.read_csv(file, nrows=5, header=None, sep=&quot;\t&quot;, comment=&quot;#&quot;, na_values=&quot;Nothing&quot;)

</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="pickle" prog_lang="custom-colors" readonly="False" tags="pickle" ts_creation="1542713565.79" ts_lastsave="1542715341.59" unique_id="18">
			<rich_text scale="h1">Pickle</rich_text>
			<rich_text>

Loading data with pickle

The pickle module allows us to save Python objects that cannot usually be easily saved in text format.


</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text weight="heavy">Question: How to save objects in pickle format?</rich_text>
			<codebox char_offset="139" frame_height="145" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import pickle package
import pickle

# Open pickle file and load data: d
with open('data.pkl', &quot;rb&quot;) as file:
    d = pickle.load(file)
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Excel" prog_lang="custom-colors" readonly="False" tags="excel data import" ts_creation="1542713007.11" ts_lastsave="1542989125.01" unique_id="17">
			<rich_text scale="h1">Excel</rich_text>
			<rich_text>

Loading data from excel files

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Alternative way to read excel files using pandas from Importing Data in Python Part 2

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>



</rich_text>
			<codebox char_offset="38" frame_height="520" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import pandas
import pandas as pd

# Load spreadsheet: xl
xl = pd.ExcelFile(&quot;battledeath.xlsx&quot;)

# Print sheet names - this will return a list of strings
print(xl.sheet_names)

# Load a sheet into a DataFrame by name: df1 - this assumes that there is a sheet named &quot;2004&quot;
# skiprows is a list of indices of the rows to skip
# names is a list of the names we assign to the columns imported
df1 = xl.parse(&quot;2004&quot;, skiprows=[0], names=[&quot;Country&quot;,&quot;AAM due to War (2004)&quot;])

# Print the head of the DataFrame df1
print(df1.head())

# Parse the first column of the second sheet and rename the column: df2
# parse_cols is a list of the indices of the columns to parse. Here names give the name assigned to this column
df2 = xl.parse(&quot;2004&quot;, parse_cols=[0], skiprows=[0], names=[&quot;Country&quot;])

</codebox>
			<codebox char_offset="128" frame_height="115" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import pandas as pd
url = 'http://my.url/data.xls'
xl = pd.read_excel(url,sheetname=None)
print(xl.keys()) # prints the sheetnames - individual sheets can be referenced as if xl was a dictionary</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="SAS and Stata" prog_lang="custom-colors" readonly="False" tags="SAS Stata" ts_creation="1542713903.03" ts_lastsave="1542715304.68" unique_id="19">
			<rich_text scale="h1">SAS and Stata</rich_text>
			<rich_text>

Here's how we import SAS files

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>



Here's how we import Stata files

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<codebox char_offset="47" frame_height="175" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Pandas has already been imported

# Import sas7bdat package
from sas7bdat import SAS7BDAT

# Save file to a DataFrame: df_sas - this is a pandas data frame
with SAS7BDAT('sales.sas7bdat') as file:
    df_sas=file.to_data_frame()
</codebox>
			<codebox char_offset="86" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import pandas
import pandas as pd

# Load Stata file into a pandas DataFrame: df
df = pd.read_stata(&quot;disarea.dta&quot;)
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="HDF5" prog_lang="custom-colors" readonly="False" tags="HDF5" ts_creation="1542714323.61" ts_lastsave="1542800518.61" unique_id="20">
			<rich_text scale="h1">HDF5</rich_text>
			<rich_text>

Here's how we import HDF5 files

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


Data is stored in separate sections and we can view them as if it were a dictionary. Certain sections may contain a “table of content” of sorts for the data set.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


Once we have identified the data we want, we can access it through its label. This subsection will have sub-keys.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>
</rich_text>
			<codebox char_offset="39" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import the h5py module
import h5py

# Load file: data
data = h5py.File(&quot;LIGO_data.hdf5&quot;,&quot;r&quot;)
</codebox>
			<codebox char_offset="206" frame_height="85" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Print the keys of the file
for key in data.keys():
    print(key)

</codebox>
			<codebox char_offset="325" frame_height="205" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">group=data[&quot;strain&quot;]

# Check out keys of group
for key in group.keys():
    print(key)

# Set variable equal to time series data: strain
# strain can be plotted
strain=data['strain'][&quot;Strain&quot;].value
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="SQL" prog_lang="custom-colors" readonly="False" tags="sql" ts_creation="1542800512.04" ts_lastsave="1543084039.51" unique_id="21">
			<rich_text scale="h1">SQL</rich_text>
			<rich_text>

Common DB types: Postgresql, MySQL, SQLite, 

This is how we open the database, run a basic query, and import it into a pandas data frame.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


Fetch only a certain number of rows.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Running queries from pandas</rich_text>
			<rich_text>

We can alternatively run the query from pandas

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>







WHat is the pro and cons of using the pandas way to execute a SQL query?

Revise INNER JOIN, OUTER JOIN and different types of joins</rich_text>
			<codebox char_offset="145" frame_height="415" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Import necessary module
from sqlalchemy import create_engine
from pandas import pd

# Create engine: engine
engine = create_engine(&quot;sqlite:///Chinook.sqlite&quot;)

# a list of table names in the DB can be accessed through the table_names() method
table_names = engine.table_names()

con = engine.connect()
# We can replace the above line with a context manager with statement
# with engine.connect() as con:
#     ....
rs = con.execute(&quot;SELECT * FROM Table_Name&quot;)
df = pd.DataFrame(rs.fetchall())
df.columns = rs.keys() # Set the column names to be the same as that in the DB
con.close()</codebox>
			<codebox char_offset="187" frame_height="40" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">df = pd.DataFrame(rs.fetchmany(size=5))</codebox>
			<codebox char_offset="267" frame_height="55" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">df = pd.read_sql_query(&quot;SELECT * FROM Table&quot;, engine)
</codebox>
			<node custom_icon_id="0" foreground="" is_bold="False" name="Basic SQL Syntax" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1543082608.26" ts_lastsave="1543084021.69" unique_id="28">
				<rich_text scale="h1">Basic SQL Syntax</rich_text>
				<rich_text>

</rich_text>
				<rich_text justification="left"></rich_text>
				<codebox char_offset="18" frame_height="415" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="sql" width_in_pixels="True">-- Selects all records in all columns from table
SELECT * FROM Table_Name;

-- Selects only certain columns from the table
SELECT col1, col2, col3 FROM Table_Name;

-- Display only those records which satisfies a certain condition on a certain column
SELECT * FROM Table_Name WHERE col1 &gt;= 6;

-- Select all records but sort them by a certain column
SELECT * FROM Employee ORDER BY BirthDate;

-- Performs inner join. Displays only certain columns selected from two tables. Specifies which column to use as the joining key
SELECT Title, Name FROM Album INNER JOIN Artist on Album.ArtistID = Artist.ArtistID;

-- Another example of multiple table query
SELECT * FROM PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId=Track.TrackID WHERE Milliseconds &lt; 250000;</codebox>
			</node>
		</node>
	</node>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Importing Data in Python Part 2" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542988073.09" ts_lastsave="1543084212.47" unique_id="22">
		<rich_text></rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="urllib" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542988172.07" ts_lastsave="1543082459.11" unique_id="23">
			<rich_text>
</rich_text>
			<rich_text scale="h1">Importing flat/data files directly from the web</rich_text>
			<rich_text>

Using urllib
</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Or directly using pandas

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Importing excel files can be done as well

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<codebox char_offset="63" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">from urllib.requests import urlretrieve
url = &quot;http://some.url/data.csv&quot;
urlretrieve(url, &quot;localdata.csv&quot;)
</codebox>
			<codebox char_offset="92" frame_height="40" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">df=pd.read_csv(url,sep=&quot;;&quot;)</codebox>
			<codebox char_offset="138" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import pandas as pd
url = 'http://my.url/data.xls' # this can be other supported protocols such as ftp. Local file can be referenced with file:///
xl = pd.read_excel(url,sheetname=None)
print(xl.keys()) # prints the sheetnames - individual sheets can be referenced as if xl was a dictionary</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="HTML requests" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542989430.82" ts_lastsave="1543082474.39" unique_id="24">
			<rich_text scale="h1">HTTP GET requests</rich_text>
			<rich_text>

Using urllib

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Using requests module

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

The response object also has a json() method to parse any API JSON response.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<codebox char_offset="33" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">from urllib.request import urlopen, Request
url = &quot;http://my.url&quot;
request = Request(url)
response = urlopen(request)
html = response.read()
response.close()</codebox>
			<codebox char_offset="59" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import requests
url = &quot;http://my.url&quot;
r = requests.get(url)
text = r.text</codebox>
			<codebox char_offset="140" frame_height="70" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">json_data = r.json()
#json_data is a dictionary and can be accessed like key-value pairs
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="BeautifulSoup" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1542990129.82" ts_lastsave="1543082491.31" unique_id="25">
			<rich_text scale="h1">Using BeautifulSoup</rich_text>
			<rich_text>

Starting </rich_text>
			<rich_text link="node 25">BeautifulSoup</rich_text>
			<rich_text>

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Then we can do things to the soup.

Prettify it

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Get the title

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Get the text

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Find tags

</rich_text>
			<rich_text justification="left"></rich_text>
			<codebox char_offset="45" frame_height="130" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">from bs4 import BeautifulSoup
import requests
url = &quot;http://my.url&quot;
r = requests.get(url)
html_doc = r.text
soup = BeautifulSoup(html_doc)</codebox>
			<codebox char_offset="97" frame_height="70" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># pretty soup is a properly indented soup object
pretty_soup = soup.prettify()</codebox>
			<codebox char_offset="115" frame_height="55" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># this string contains the &lt;title&gt; tags
title = soup.title</codebox>
			<codebox char_offset="132" frame_height="55" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># This string contains no tags, only the textual part of the page
text = soup.text</codebox>
			<codebox char_offset="146" frame_height="190" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">a_tags = soup.find_all('a') # finds all a tags -usually these will have urls
# a_tags is of the type ResultSet - this is an iterable
# link is a Tag object. Printing it gives the results together with the tags
# calling the method get('href') filters the result to give only those with href
for link in a_tags:
    print(link.get('href'))</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="JSON" prog_lang="custom-colors" readonly="False" tags="json" ts_creation="1543079116.75" ts_lastsave="1543082504.53" unique_id="26">
			<rich_text scale="h1">Importing data from JSON objects</rich_text>
			<rich_text>

JSON  stands for Javascript Object Notation

Has a key value pair structure and is text readable. The value themselves can in turn be json objects.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

The requests module also has a method for the response object to  turn JSON responses into key value pairs. See the </rich_text>
			<rich_text link="node 24">HTML requests node</rich_text>
			<rich_text>.

</rich_text>
			<codebox char_offset="183" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import json
# json_data is a dictionary
with open('file.json', 'r') as json_file:
    json_data = json.load(json_file)

</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="APIs" prog_lang="custom-colors" readonly="False" tags="API" ts_creation="1543080225.62" ts_lastsave="1543084190.58" unique_id="27">
			<rich_text scale="h1">Miscellaneous information about APIs</rich_text>
			<rich_text>

REST stands for Representational State Transfer


Authenticating to Twitter API

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>
</rich_text>
			<codebox char_offset="119" frame_height="160" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import tweepy, json
access_token = &quot;...&quot;
access_token_secret = &quot;...&quot;
consumer_key = &quot;...&quot;
consumer_secret = &quot;...&quot;
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)</codebox>
		</node>
	</node>
	<node custom_icon_id="0" foreground="" is_bold="False" name="Cleaning Data in Python" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1543084190.59" ts_lastsave="1543644784.13" unique_id="29">
		<rich_text>


</rich_text>
		<rich_text underline="single" weight="heavy">Common problems of unclean data</rich_text>
		<rich_text>

• Inconsistent column names
• Missing data
• Outliers
• Duplicate rows
• Need to process columns
• Column types signal unexpected values

</rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Useful methods for data inspection" prog_lang="custom-colors" readonly="False" tags="inspecting data" ts_creation="1543084457.13" ts_lastsave="1543483015.45" unique_id="30">
			<rich_text>

</rich_text>
			<rich_text justification="left"></rich_text>
			<codebox char_offset="2" frame_height="565" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># assuming df is a pandas data frame

# Check out the first five rows of data
print(df.head())

# Check out the last five rows of data
print(df.tail())

# print the number of rows and columns of this data set in (rows, cols) format - note that this is not a method
print(df.shape)

# print the names of the columns - note that this is not a method
print(df.columns)

# print out info about the types of objects in each column, how many nulls there are etc
print(df.info())

# print out summary statistics such as count, mean, median, std, max, quartiles for numeric columns
df.describe()

# print the count of occurences for various categories, including NA
# applies to categorical data only
print(df['Column Name'].value_counts(dropna=False))

</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Melting, Pivoting and Splitting" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1543420088.28" ts_lastsave="1543507687.21" unique_id="31">
			<rich_text scale="h1">Melting</rich_text>
			<rich_text>

Melting - doing away with certain chosen columns and putting the values associated with those attributes into rows.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

We can assign names to the new columns of the melted data frame through var_name and value_name.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Pivoting</rich_text>
			<rich_text>

This is the opposite of melting.
</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Note that the above is not quite the original data frame - it's got a hierachical index aka Multiindex.

We can reset the index to get back what we want. This is covered in more depth in a later chapter.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Pivoting with aggregation function to deal  with duplicates. The default aggregation function used is np.mean if no aggfunc argument is specified.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


</rich_text>
			<rich_text weight="heavy">Q: Does the function supplied to the pivot_table method need to be a numpy function?
Q: There are two ways to reference columns - either by df[&quot;colname&quot;] or df.colname. Are there situations where only one way works? Personally i prefer the former. WOn't there be ambiguity when the column name contains a dot ‘.’?
</rich_text>
			<rich_text>

</rich_text>
			<rich_text scale="h1">Splitting strings</rich_text>
			<rich_text>

This is how we split strings and create new columns. Note how we apply the str attribute

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Split() and get() methods

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>




</rich_text>
			<codebox char_offset="126" frame_height="145" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># id_vars represents the columns that we DO NOT wish to melt
# value_vars represents the columns that we DO wish to melt
# by default, if no value_vars is defined, all columns not in id_vars will be melted
melted_frame = pd.melt(frame=unmelted_frame, id_vars = ['col1','col2'], value_vars = ['meltcol1','meltcol2'])
</codebox>
			<codebox char_offset="227" frame_height="100" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Melt airquality: airquality_melt
airquality_melt = pd.melt(frame=airquality, id_vars=[&quot;Month&quot;,&quot;Day&quot;], var_name=&quot;measurement&quot;, value_name=&quot;reading&quot;)
</codebox>
			<codebox char_offset="273" frame_height="445" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># original data frame
#    Month  Day measurement  reading
# 0      5    1       Ozone     41.0
# 1      5    2       Ozone     36.0
# 2      5    3       Ozone     12.0
# 3      5    4       Ozone     18.0
# 4      5    5       Ozone      NaN


# Pivot airquality_melt: airquality_pivot
airquality_pivot = airquality_melt.pivot_table(index=[&quot;Month&quot;, &quot;Day&quot;], columns=&quot;measurement&quot;, values=&quot;reading&quot;)

# This transforms the data frame back into this
# measurement  Ozone  Solar.R  Temp  Wind
# Month Day                              
# 5     1       41.0    190.0  67.0   7.4
#       2       36.0    118.0  72.0   8.0
#       3       12.0    149.0  74.0  12.6
#       4       18.0    313.0  62.0  11.5
#       5        NaN      NaN  56.0  14.3
</codebox>
			<codebox char_offset="481" frame_height="190" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Print the index of airquality_pivot
print(airquality_pivot.index)

# Reset the index of airquality_pivot: airquality_pivot_reset
airquality_pivot_reset = airquality_pivot.reset_index()

# Print the new index of airquality_pivot_reset
print(airquality_pivot_reset)
</codebox>
			<codebox char_offset="632" frame_height="145" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Pivot airquality_dup: airquality_pivot
airquality_pivot = airquality_dup.pivot_table(index=[&quot;Month&quot;,&quot;Day&quot;], columns=&quot;measurement&quot;, values=&quot;reading&quot;, aggfunc=np.mean)

# Reset the index of airquality_pivot
airquality_pivot = airquality_pivot.reset_index()
</codebox>
			<codebox char_offset="1061" frame_height="355" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Melt tb: tb_melt
tb_melt = pd.melt(frame=tb, id_vars=[&quot;country&quot;, &quot;year&quot;])

# Create the 'gender' column
tb_melt['gender'] = tb_melt.variable.str[0]

# Create the 'age_group' column
tb_melt['age_group'] = tb_melt.variable.str[1:]


# The result looks like this
#   country  year variable  value gender age_group
# 0      AD  2000     m014    0.0      m       014
# 1      AE  2000     m014    2.0      m       014
# 2      AF  2000     m014   52.0      m       014
# 3      AG  2000     m014    0.0      m       014
# 4      AL  2000     m014    2.0      m       014
</codebox>
			<codebox char_offset="1091" frame_height="430" frame_width="100" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="False"># Original data frame looks a bit like this (many columns omitted)
#         Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  \
#0    1/5/2015  289        2776.0            NaN            10030.0   
#1    1/4/2015  288        2775.0            NaN             9780.0   
#2    1/3/2015  287        2769.0         8166.0             9722.0   
#3    1/2/2015  286           NaN         8157.0                NaN   
#4  12/31/2014  284        2730.0         8115.0             9633.0   


# Melt ebola: ebola_melt
ebola_melt = pd.melt(ebola, id_vars=[&quot;Date&quot;, &quot;Day&quot;], var_name=&quot;type_country&quot;, value_name=&quot;counts&quot;)

# Create the 'str_split' column
# This also seems to work: ebola_melt['str_split'] = ebola_melt.type_country.str.split(&quot;_&quot;)
ebola_melt['str_split'] = ebola_melt[&quot;type_country&quot;].str.split(&quot;_&quot;)

# Create the 'type' column
ebola_melt['type'] = ebola_melt[&quot;str_split&quot;].str.get(0)

# Create the 'country' column
ebola_melt['country'] = ebola_melt[&quot;str_split&quot;].str.get(1)
</codebox>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="Combining data" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1543644784.14" ts_lastsave="1543647059.44" unique_id="32">
			<rich_text>
Concatenating data - adding rows

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Adding columns - specify axis=1 as an argument. If omitted, axis=0, as is the case above.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>

Finding files in the local workspace - first we find all files matching a certain pattern using glob.


</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


Merging data frames - this is in cases where two data frames have a common column we can use to merge the data.
left_on and right_on are the column names of the common column.
1-1, many-1, 1-many merging all use the same code. Think about different types of JOINs in SQL.

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>


TIP: If columns are replaced by ... when using head or tail methods, we can view and configure the behaviours through the pandas get_options and set_option methods

</rich_text>
			<rich_text justification="left"></rich_text>
			<rich_text>
</rich_text>
			<codebox char_offset="35" frame_height="175" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># uber1, uber2 and uber3 are data frames
# pandas as been imported as pd
# Concatenate uber1, uber2, and uber3: row_concat
row_concat = pd.concat([uber1,uber2,uber3])

# To use running indices in the new data frame, add an ignore_index argument
row_concat = pd.concat([uber1,uber2,uber3], ignore_index=True)</codebox>
			<codebox char_offset="129" frame_height="70" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Concatenate ebola_melt and status_country column-wise: ebola_tidy
ebola_tidy = pd.concat([ebola_melt,status_country],axis=1)
</codebox>
			<codebox char_offset="236" frame_height="175" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">import glob

# Write the pattern: pattern
pattern = '*.csv'

# Save all file matches: csv_files - this is a list of filenames which we can use for importing in pandas
csv_files = glob.glob(pattern)
</codebox>
			<codebox char_offset="513" frame_height="85" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True"># Merge the DataFrames: o2o
o2o = pd.merge(left=site, right=visited, left_on=&quot;name&quot;, right_on=&quot;site&quot;)
</codebox>
			<codebox char_offset="682" frame_height="115" frame_width="700" highlight_brackets="True" show_line_numbers="False" syntax_highlighting="python3" width_in_pixels="True">
pd.get_option(&quot;display.max_columns&quot;)

pd.set_option(&quot;display.max_columns&quot;,10)
</codebox>
		</node>
	</node>
</cherrytree>
